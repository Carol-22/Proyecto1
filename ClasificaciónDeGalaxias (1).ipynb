{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d85652e-610c-423b-8418-f909c060010b",
   "metadata": {},
   "source": [
    "# Proyecto 2: Filtros de imágenes \n",
    "## Clasificación de Galaxias con Deep Learning \n",
    " Carol Edith Quiñones Sánchez "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0be1155-215b-4257-a685-3a6cef43b9c9",
   "metadata": {},
   "source": [
    "#### Para diseñar una red neuronal capaz de clasificar 3 tipos de galaxias, elípticas, espirales y barradas es necesario usar filtros de textura con arquitectura de CNN. Esto es necesario para poder distinguir la forma de cada galaxía y así hacer una ditinción entre cada tipo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b7277e31-2798-41d2-8e62-a3b3cf235779",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ---- Importación de librerias --- ###\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "58bcd8d3-5491-4aec-9056-b62f7ce1e9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Configuration de datos --- ###\n",
    "DATA_DIR = \"galaxys1\"\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 16\n",
    "NUM_CLASSES = 5 # número de clases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "fb33c9f7-125d-46df-bc9c-0bdb461c5e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints', 'Barradas', 'Elipticas', 'Espirales']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualización de carpetas que contienen la imagenes \n",
    "os.listdir('galaxys1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9392e1a6-efdf-457f-8ed7-aa2d05ab623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Pre-procesamiento de filtros clásicos --- ###\n",
    "def apply_classical_filters(img):\n",
    "    # Escala de gris para imágenes \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Sobel X + Y (3x3) resalta bordes horizontales y verticales\n",
    "    sobel_x = cv2.Sobel(gray, cv2.CV_32F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=3)\n",
    "    \n",
    "    # Laplaciano (3x3) detecta direcciones de cambio de intensidad\n",
    "    laplacian = cv2.Laplacian(gray, cv2.CV_32F, ksize=3)\n",
    "    \n",
    "    # Ecualización adaptativa de histograma (CLAHE) mejora contraste en regiones debiles de luminosidad\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    hc = clahe.apply(gray)\n",
    "    # Blur Gaussiano (5x5) elimina ruido de fondo antes de detectar bordes\n",
    "    blurred = cv2.GaussianBlur(img, (5,5), sigmaX=1.0)\n",
    "    \n",
    "     # Normalizar cada canal al rango [0,1]\n",
    "    sobel_x = cv2.normalize(sobel_x, None, 0, 1, cv2.NORM_MINMAX)\n",
    "    sobel_y = cv2.normalize(sobel_y, None, 0, 1, cv2.NORM_MINMAX)\n",
    "    laplacian = cv2.normalize(laplacian, None, 0, 1, cv2.NORM_MINMAX)\n",
    "    hc = hc.astype(np.float32) / 255.0\n",
    "    blurred = blurred.astype(np.float32) / 255.0\n",
    "    # Reescalar imagen original a [0,1]\n",
    "    img_norm = img.astype(np.float32) / 255.0\n",
    "    \n",
    "    # Concatenar canales: RGB + SobelX + SobelY + Laplacian + CLAHE_gray\n",
    "    combined = np.concatenate([\n",
    "        img_norm,                            # 3 canales\n",
    "        np.expand_dims(sobel_x, -1),        # 1 canal\n",
    "        np.expand_dims(sobel_y, -1),        # 1 canal\n",
    "        np.expand_dims(laplacian, -1),      # 1 canal\n",
    "        np.expand_dims(hc, -1)              # 1 canal\n",
    "    ], axis=-1)\n",
    "    \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "40bb6edd-55ff-4514-bc7b-e3ea072fac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNELS = 3 + 4  # 3 RGB + 4 filtros clásicos\n",
    "\n",
    "ds = (\n",
    "    paths_ds\n",
    "    .shuffle(buffer_size=len(file_paths), reshuffle_each_iteration=True)\n",
    "    .map(lambda p, l: tf.py_function(\n",
    "             func=load_and_preprocess,\n",
    "             inp=[p, l],\n",
    "             Tout=(tf.float32, tf.int32)),\n",
    "         num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    # <- Aquí corregimos la forma faltante:\n",
    "    .map(lambda img, lbl: (\n",
    "         tf.ensure_shape(img, IMG_SIZE + (CHANNELS,)),\n",
    "         tf.ensure_shape(lbl, [])\n",
    "    ))\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "96efaf1c-3ca0-4c0d-9766-c154453fb15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess(path, label):\n",
    "    # 1) Extrae el string del tensor\n",
    "    path_str = path.numpy().decode(\"utf-8\")\n",
    "    lbl      = label.numpy()           # si quieres un numpy int\n",
    "    \n",
    "    # 2) Lee y procesa la imagen\n",
    "    img = cv2.imread(path_str)\n",
    "    img = cv2.resize(img, IMG_SIZE)\n",
    "    \n",
    "    # (si usas filtros clásicos)\n",
    "    filtered = apply_classical_filters(img)\n",
    "    \n",
    "    # 3) Devuelve NumPy arrays de tipo correcto\n",
    "    return filtered.astype(np.float32), np.int32(lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbb4e2b-68ca-4e46-b801-ff9212b1800a",
   "metadata": {},
   "source": [
    "##### (3x3) detecta bordes y esquinas (Workhorse de la mayoria de arquitecturas).\n",
    "##### (5x5) capta texturas de mayor escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "cbcc552c-6a4b-4e6f-a4fd-7f7cca998f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_ds = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
    "\n",
    "ds = (\n",
    "    paths_ds\n",
    "    .shuffle(buffer_size=len(file_paths), reshuffle_each_iteration=True)\n",
    "    .map(lambda p, l: tf.py_function(\n",
    "             func=load_and_preprocess,\n",
    "             inp=[p, l],\n",
    "             Tout=(tf.float32, tf.int32)),\n",
    "         num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .map(lambda img, lbl: (\n",
    "         tf.ensure_shape(img, IMG_SIZE + (CHANNELS,)),\n",
    "         tf.ensure_shape(lbl, [])))\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e0410bc9-e458-4788-84c2-5918f1e74a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Cargar rutas de archivos y etiquetas --- ###\n",
    "class_names = sorted([d for d in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, d))])\n",
    "file_paths = []\n",
    "labels = []\n",
    "for idx, cls in enumerate(class_names):\n",
    "    cls_dir = os.path.join(DATA_DIR, cls)\n",
    "    for fname in os.listdir(cls_dir):\n",
    "        if fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            file_paths.append(os.path.join(cls_dir, fname))\n",
    "            labels.append(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "5d61f56b-77b1-4b45-adbe-f7292e4d81ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Convertir a Dataset --- ###\n",
    "paths_ds = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
    "ds = paths_ds.shuffle(len(file_paths)) \\\n",
    "             .map(lambda p, l: tf.py_function(func=load_and_preprocess, inp=[p, l], Tout=(tf.float32, tf.int32)),\n",
    "                  num_parallel_calls=tf.data.AUTOTUNE) \\\n",
    "             .batch(BATCH_SIZE) \\\n",
    "             .prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "620d8fcd-96c6-4478-9d3b-0758507c5d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Modelo CNN simple --- ###\n",
    "input_shape = IMG_SIZE + (3 + 4,)  # 3 canales RGB + 4 filtros clásicos\n",
    "inputs = layers.Input(shape=input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "512505bc-2118-45a5-86cc-92bec72045c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "bd686143-6457-4e2f-bd3b-dfbe2af7416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "763da96b-e8c6-4aff-ad1d-ebdfeab4ad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Conv2D(128, 3, dilation_rate=2, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "bd64c2be-ac7e-4b86-b597-260d3ace24ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f0ed2f93-66c9-4455-b960-de33a41073bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_18               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_19               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_20               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,285</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_30 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_18               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_31 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m9,248\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_12 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_32 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_19               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_33 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m36,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_13 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_34 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_20               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m33,024\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │           \u001b[38;5;34m1,285\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">175,781</span> (686.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m175,781\u001b[0m (686.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">175,333</span> (684.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m175,333\u001b[0m (684.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = models.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.build((None, IMG_SIZE[0], IMG_SIZE[1], CHANNELS))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "cbf4cdeb-2fd7-4d10-8740-ffd1e1fe4ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    run_eagerly=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "914e555a-8621-4292-8b4c-dba1b7b46c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.1945 - loss: 1.6938\n",
      "Epoch 2/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.5685 - loss: 1.2320\n",
      "Epoch 3/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.6650 - loss: 1.0394\n",
      "Epoch 4/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.6001 - loss: 1.0012\n",
      "Epoch 5/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.6616 - loss: 0.8278\n",
      "Epoch 6/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.7092 - loss: 0.7597\n",
      "Epoch 7/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.6195 - loss: 0.8419\n",
      "Epoch 8/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.6885 - loss: 0.8003\n",
      "Epoch 9/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.7820 - loss: 0.6364\n",
      "Epoch 10/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.7864 - loss: 0.5993\n",
      "Epoch 11/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7091 - loss: 0.6866\n",
      "Epoch 12/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.7360 - loss: 0.6404\n",
      "Epoch 13/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7352 - loss: 0.6349\n",
      "Epoch 14/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.7733 - loss: 0.5806\n",
      "Epoch 15/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.8789 - loss: 0.4669\n",
      "Epoch 16/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.6434 - loss: 0.7028\n",
      "Epoch 17/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.8048 - loss: 0.4914\n",
      "Epoch 18/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7961 - loss: 0.4531\n",
      "Epoch 19/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.8002 - loss: 0.4273\n",
      "Epoch 20/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.8193 - loss: 0.4838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x196cae3f750>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f1c8c1e5-c2bd-4d90-9816-361ea920fd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Guardar modelo\n",
    "model.save(\"galaxy_classifier_with_filters.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "09a3d6b7-686e-4e3b-a786-9608996db59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Parámetros --- ###\n",
    "IMG_SIZE  = (224, 224)\n",
    "CHANNELS  = 3 + 4   # 3 RGB + 4 filtros clásicos\n",
    "CLASS_NAMES = [\"Barrada\", \"Espiral\", \"Eliptica\", \"...\"]  # tus clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "4eee195b-0c0b-4216-a46d-b71e3ddf04a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "### --- Carga el modelo --- ###\n",
    "model = load_model(\"galaxy_classifier_with_filters.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "f872059d-81ec-4783-98df-3b243810b076",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Define la misma función de filtros --- ### \n",
    "def apply_classical_filters(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    sobel_x = cv2.normalize(cv2.Sobel(gray, cv2.CV_32F, 1, 0, ksize=3),\n",
    "                             None, 0, 1, cv2.NORM_MINMAX)\n",
    "    sobel_y = cv2.normalize(cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=3),\n",
    "                             None, 0, 1, cv2.NORM_MINMAX)\n",
    "    laplacian = cv2.normalize(cv2.Laplacian(gray, cv2.CV_32F, ksize=3),\n",
    "                               None, 0, 1, cv2.NORM_MINMAX)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)).apply(gray)\n",
    "    clahe = clahe.astype(np.float32) / 255.0\n",
    "\n",
    "    img_norm = img.astype(np.float32) / 255.0\n",
    "    blurred  = cv2.GaussianBlur(img_norm, (5,5), sigmaX=1.0)\n",
    "\n",
    "    return np.concatenate([\n",
    "        img_norm,\n",
    "        sobel_x[...,None],\n",
    "        sobel_y[...,None],\n",
    "        laplacian[...,None],\n",
    "        clahe[...,None]\n",
    "    ], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "a03cb3da-8200-4572-8a0c-304312b4bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Predicción de una imagen --- ### \n",
    "def predict_image(path_to_image):\n",
    "    # Redimenciona\n",
    "    img = cv2.imread(path_to_image)\n",
    "    img = cv2.resize(img, IMG_SIZE)\n",
    "    # Aplicación de filtros y normalización\n",
    "    x   = apply_classical_filters(img)\n",
    "    # Crea batch de tamaño 1\n",
    "    x   = np.expand_dims(x, axis=0)   # shape (1, 224,224,7)\n",
    "    # Predección\n",
    "    probs = model.predict(x)[0]       # vector de probabilidades\n",
    "    idx   = np.argmax(probs)          # índice de la clase más probable\n",
    "    return CLASS_NAMES[idx], probs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "b6a8b33d-1245-4653-9de1-e9e793cfac17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "Predicción: Eliptica (confianza=82.8%)\n"
     ]
    }
   ],
   "source": [
    "### --- EJEMPLO --- ###\n",
    "imagen = \"galaxys1/Elipticas/Colliding Galaxies NGC 1410 and NGC 1409.png\"\n",
    "clase, confianza = predict_image(imagen)\n",
    "print(f\"Predicción: {clase} (confianza={confianza*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8811625-177c-40e8-b591-f564b46a8de4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
